# Research Guide - Steve AI Project

**Project:** Steve AI - "Cursor for Minecraft"
**Status:** Research & Development (Active Building Phase)
**Updated:** 2026-02-28
**Version:** 1.0

---

## Table of Contents

1. [Research Overview](#research-overview)
2. [Dissertation Status](#dissertation-status)
3. [Chapter Status](#chapter-status)
4. [Where Research Lives](#where-research-lives)
5. [Key Research Documents](#key-research-documents)
6. [Citation Standards](#citation-standards)
7. [Adding New Research](#adding-new-research)
8. [Integration Process](#integration-process)
9. [Current Research Priorities](#current-research-priorities)
10. [Viva Voce Preparation](#viva-voce-preparation)

---

## Research Overview

### Dual Mission

The Steve AI project serves two complementary missions:

**Mission 1: Build a Great Mod**
- Create functional, fun AI-powered Minecraft companions
- Implement "One Abstraction Away" architecture
- Deliver real-time performance (60 FPS) with LLM intelligence

**Mission 2: Systemize Agent Science**
- Document patterns for AI agent development
- Contribute to academic AI research
- Produce dissertation(s) on multi-layer cognitive architectures

### Research Philosophy

**"One Abstraction Away"**

LLMs should plan and coordinate, while traditional game AI executes in real-time. This creates agents that are:
- **Fast** - 60 FPS execution without blocking on LLM calls
- **Cost-efficient** - 10-20x fewer tokens than pure LLM approaches
- **Characterful** - Rich personalities, ongoing dialogue, relationship evolution

### Core Thesis

The boundary between automatic (System 1) and thoughtful (System 2) processing is not fixed‚Äîit shifts as agents learn. LLMs can generate and refine automation scripts, reducing token usage by 10-20x while enabling richer behaviors.

---

## Dissertation Status

### Current Grade: A (94/100)

**Committee Decision:** PASS WITH MINOR REVISIONS ‚Üí APPROACHING A+

### Grade Trajectory

```
Cycle 1:      B+ (85.5/100)
Cycle 2:      A- (90/100)
Cycle 2.5:    A (92/100)
Cycle 3:      A (94/100) ‚Üê Current
Cycle 4 Target: A+ (97/100)
Cycle 5 Target: A+ (98-100/100)
```

### Path to A+ (10-15 hours remaining)

The dissertation has improved from B+ ‚Üí A- ‚Üí A through substantial content additions (~40,000 words) and integration work. The fragmentation problem is **85% resolved**.

**Completed:**
- ‚úÖ 12 Priority 1 citations implemented across Chapters 1, 3, 8
- ‚úÖ Section 8.17 (2024-2025 LLM Techniques) integrated (~5,000 words)
- ‚úÖ Citation format standardized to [Author, Year]
- ‚úÖ Performance comparison tables added

**Remaining for A+:**
- üîÑ Complete Chapter 3 emotional AI integration (~30% remaining)
- ‚è≥ Add 2024-2025 LLM technique coverage (8-10 hours)
- ‚è≥ Standardize citations across all chapters (8-10 hours)
- ‚è≥ Add limitations sections (4-6 hours)

### Integration Progress

**Overall:** 85% Complete

**Completed Chapters:**
- Chapter 1 (RTS AI): 100% ‚úÖ
- Chapter 8 (LLM Enhancement): 100% ‚úÖ
- Chapter 4 (Strategy Games): 100% ‚úÖ
- Chapter 6 (Architecture): 100% ‚úÖ

**In Progress:**
- Chapter 3 (RPG AI): ~70% complete (emotional AI sections remaining)

---

## Chapter Status

### Dissertation 1: Game AI Evolution and LLM Enhancement

| Chapter | Topic | Status | Grade | Integration | Word Count |
|---------|-------|--------|-------|-------------|------------|
| **Chapter 1** | RTS AI (Behavior Trees, HTN, Spatial) | Complete | A (93%) | 100% ‚úÖ | ~27,800 |
| **Chapter 2** | FPS AI (Finite State Machines) | Complete | A- | Complete | ~35,000 |
| **Chapter 3** | RPG AI (Emotional Systems, Companions) | In Progress | A- (91%) | 70% üîÑ | ~35,000 |
| **Chapter 4** | Strategy Games (Macro/Micro, Chunk Planning) | Complete | A | 100% ‚úÖ | ~35,280 |
| **Chapter 5** | MMO AI (Distributed Systems) | Complete | A- | Complete | ~35,000 |
| **Chapter 6** | Architecture Patterns | Complete | A- (90%) | 100% ‚úÖ | ~40,290 |
| **Chapter 7** | Design Patterns | Complete | A | Complete | ~40,000 |
| **Chapter 8** | LLM Enhancement (RAG, Tool Calling) | Complete | A (92%) | 100% ‚úÖ | ~17,200 |

### Key Improvements by Chapter

**Chapter 1 (RTS AI) - B- ‚Üí A**
- Behavior Trees: 1,721 lines (~6,900 words) with full Java implementation
- Spatial Reasoning: 2,294 lines (~9,200 words) covering potential fields, NavMesh, flow fields
- HTN (Hierarchical Task Network): 1,500+ words with performance benchmarks
- Real-Time Performance Constraints: 580+ lines on tick rate limits

**Chapter 3 (RPG AI) - B+ ‚Üí A-**
- OCC Model emotional framework (22 emotion types, full Java implementation)
- Shadow of the Colossus (Agro) - non-verbal companion AI
- The Last of Us Part II - environmental awareness, stealth cooperation
- Divinity: Original Sin 2 - tag-based personality systems
- ~5,000 words added, ~60% integrated

**Chapter 6 (Architecture) - B+ ‚Üí A-**
- Section 0: Academic Grounding with foundational citations
- Section 11.4: Multiplayer Architecture Patterns
- Citation expansion in progress
- Novelty contributions explicitly stated

**Chapter 8 (LLM Enhancement) - B+ ‚Üí A**
- RAG section: 714 lines with 84% latency reduction metrics
- Framework comparison: ReAct, AutoGPT, LangChain, BabyAGI
- Tool calling discussion: 1,321 lines covering 2022-2025 developments
- Section 8.17: 2024-2025 LLM Techniques (~5,000 words)

---

## Where Research Lives

### Directory Structure

```
C:\Users\casey\steve\docs\research\
‚îú‚îÄ‚îÄ README.md                                    # Research library index
‚îú‚îÄ‚îÄ VIVA_VOCE_CYCLE2_SYNTHESIS.md               # Examination status
‚îú‚îÄ‚îÄ DISSERTATION_INTEGRATION_SUMMARY.md         # Integration progress
‚îú‚îÄ‚îÄ CITATION_STANDARDIZATION_SUMMARY.md         # Citation guidelines
‚îÇ
‚îú‚îÄ‚îÄ DISSERTATION_CHAPTER_1_RTS_IMPROVED.md      # Main Chapter 1
‚îú‚îÄ‚îÄ DISSERTATION_CHAPTER_3_RPG_IMPROVED.md      # Main Chapter 3
‚îú‚îÄ‚îÄ DISSERTATION_CHAPTER_4_STRATEGY_IMPROVED.md # Main Chapter 4
‚îú‚îÄ‚îÄ DISSERTATION_CHAPTER_6_ARCHITECTURE_IMPROVED.md # Main Chapter 6
‚îú‚îÄ‚îÄ DISSERTATION_CHAPTER_8_LLM_ENHANCEMENT_IMPROVED.md # Main Chapter 8
‚îÇ
‚îú‚îÄ‚îÄ EVALUATION_FRAMEWORK.md                      # Academic evaluation
‚îú‚îÄ‚îÄ MUD_AUTOMATION_LLM_PRINCIPLES.md            # MUD patterns for LLMs
‚îú‚îÄ‚îÄ SCRIPT_GENERATION_SYSTEM.md                 # LLM‚ÜíScript pipeline
‚îú‚îÄ‚îÄ COGNITIVE_LAYER_ARCHITECTURE.md             # Multi-layer design
‚îÇ
‚îú‚îÄ‚îÄ PRE_LLM_GAME_AUTOMATION.md                  # Historical patterns
‚îú‚îÄ‚îÄ BEHAVIOR_TREE_EVOLUTION.md                  # BT research
‚îú‚îÄ‚îÄ BEHAVIOR_TREES_DESIGN.md                    # BT implementation
‚îú‚îÄ‚îÄ GOAP_DEEP_DIVE.md                           # Goal-Oriented Action Planning
‚îú‚îÄ‚îÄ FSM_EVOLUTION_AND_PATTERNS.md               # Finite State Machines
‚îÇ
‚îú‚îÄ‚îÄ RTS_MMO_AUTOMATION_HISTORY.md               # RTS/MMO research
‚îú‚îÄ‚îÄ RTS_MACRO_MICRO_PATTERNS.md                 # Strategy patterns
‚îú‚îÄ‚îÄ TRIGGER_WEIGHT_DECISION_SYSTEMS.md          # Decision systems
‚îÇ
‚îú‚îÄ‚îÄ MULTI_AGENT_COORDINATION.md                 # Multi-agent research
‚îú‚îÄ‚îÄ CONVERSATION_COORDINATION_DESIGN.md         # Dialogue coordination
‚îú‚îÄ‚îÄ MULTI_AGENT_ORCHESTRATION.md                # Orchestration patterns
‚îÇ
‚îú‚îÄ‚îÄ CONVERSATIONAL_MEMORY.md                    # Memory systems
‚îú‚îÄ‚îÄ MEMORY_ARCHITECTURES.md                     # Memory patterns
‚îú‚îÄ‚îÄ MEMORY_PERSISTENCE.md                       # Memory storage
‚îÇ
‚îú‚îÄ‚îÄ CHARACTER_AI_SYSTEMS.md                     # Personality systems
‚îú‚îÄ‚îÄ EMOTIONAL_AI_FRAMEWORK.md                   # Emotion modeling
‚îú‚îÄ‚îÄ HUMOR_AND_WIT.md                            # Personality traits
‚îú‚îÄ‚îÄ RELATIONSHIP_MILESTONES.md                  # Relationship evolution
‚îÇ
‚îú‚îÄ‚îÄ VOICE_INTEGRATION.md                        # Voice system
‚îú‚îÄ‚îÄ LLM_PROMPT_OPTIMIZATION.md                  # Prompt engineering
‚îú‚îÄ‚îÄ LLM_TOOL_CALLING.md                         # Tool calling research
‚îú‚îÄ‚îÄ TOKEN_EFFICIENCY_PATTERNS.md                # Cost optimization
‚îÇ
‚îú‚îÄ‚îÄ AI_AGENT_FRAMEWORKS.md                      # Framework comparison
‚îú‚îÄ‚îÄ AI_AGENT_PATTERNS_2025.md                   # Modern agent patterns
‚îú‚îÄ‚îÄ CHAPTER_8_LLM_FRAMEWORK_COMPARISON.md       # Framework analysis
‚îÇ
‚îú‚îÄ‚îÄ ARCHITECTURE_A_EVENT_DRIVEN.md              # Event-driven design
‚îú‚îÄ‚îÄ ARCHITECTURE_B_STATE_MACHINE.md             # State machine patterns
‚îú‚îÄ‚îÄ ARCHITECTURE_C_BLACKBOARD.md                # Blackboard pattern
‚îú‚îÄ‚îÄ ARCHITECTURE_COMPARISON.md                  # Architecture comparison
‚îÇ
‚îú‚îÄ‚îÄ COMPREHENSIVE_BIBLIOGRAPHY.md               # 87 sources
‚îú‚îÄ‚îÄ CITATION_EDITS_QUICK_REFERENCE.md           # Citation guide
‚îú‚îÄ‚îÄ CITATION_PROGRESS_TRACKER.md                # Citation tracking
‚îÇ
‚îî‚îÄ‚îÄ [100+ additional research documents...]
```

### File Categories

**Dissertation Chapters (8 files)**
- Main content: `DISSERTATION_CHAPTER_[1-8]_*_IMPROVED.md`
- Source material: `DISSERTATION_CHAPTER_*_[TOPIC].md`

**Game AI Research (15+ files)**
- Behavior Trees, FSMs, HTN, GOAP
- RTS, FPS, RPG, MMO patterns
- Historical evolution (1990s-2020s)

**LLM Integration (10+ files)**
- Tool calling, RAG, prompting
- Framework comparisons (ReAct, AutoGPT, LangChain)
- 2024-2025 techniques

**Architecture & Design (12+ files)**
- Event-driven, state machine, blackboard
- Multi-layer cognitive architecture
- Microservices, resilience patterns

**Memory & Learning (8+ files)**
- Conversational memory
- Vector embeddings
- Script layer learning

**Multi-Agent Systems (6+ files)**
- Coordination patterns
- Contract Net Protocol
- Orchestration frameworks

**Evaluation & Testing (5+ files)**
- Benchmark scenarios
- Metrics collection
- Statistical analysis

**Citations & Bibliography (4+ files)**
- 87 sources catalogued
- Citation format standards
- Progress tracking

---

## Key Research Documents

### Must-Read Files (Priority Order)

**1. VIVA_VOCE_CYCLE2_SYNTHESIS.md**
- **Purpose:** Examination status and grade trajectory
- **Key Content:** Current grade A (94/100), 85% integration complete, path to A+
- **When to Read:** First - understand current status

**2. DISSERTATION_INTEGRATION_SUMMARY.md**
- **Purpose:** Detailed integration progress
- **Key Content:** Chapter-by-chapter integration status, orphaned files resolved
- **When to Read:** Second - understand what's been integrated

**3. CITATION_STANDARDIZATION_SUMMARY.md**
- **Purpose:** Citation guidelines and standards
- **Key Content:** [Author, Year] format, 87 sources, 33 edits required
- **When to Read:** Before adding citations

**4. COGNITIVE_LAYER_ARCHITECTURE.md**
- **Purpose:** Multi-layer cognitive architecture design
- **Key Content:** Brain/Script/Physical layers, "One Abstraction Away" philosophy
- **When to Read:** Understand core architecture

**5. EVALUATION_FRAMEWORK.md**
- **Purpose:** Academic evaluation methodology
- **Key Content:** Benchmark scenarios, metrics, statistical analysis
- **When to Read:** Before designing experiments

**6. MUD_AUTOMATION_LLM_PRINCIPLES.md**
- **Purpose:** Historical patterns for modern LLM agents
- **Key Content:** TinTin++, ZMUD patterns translated to LLM systems
- **When to Read:** Understanding automation fundamentals

**7. SCRIPT_GENERATION_SYSTEM.md**
- **Purpose:** LLM‚ÜíScript pipeline design
- **Key Content:** Script extraction, refinement, automatic promotion
- **When to Read:** Understanding learning system

**8. CHAPTER_8_2024_2025_TECHNIQUES.md**
- **Purpose:** Modern LLM technique coverage
- **Key Content:** Native structured output, small models, agent frameworks
- **When to Read:** Understanding current LLM capabilities

### Research Area Deep Dives

**Game AI Foundations:**
- `BEHAVIOR_TREE_EVOLUTION.md` - BT history and patterns
- `GOAP_DEEP_DIVE.md` - Goal-Oriented Action Planning
- `FSM_EVOLUTION_AND_PATTERNS.md` - Finite State Machines
- `PRE_LLM_GAME_AUTOMATION.md` - Historical automation (1990s-2020s)

**LLM Integration:**
- `LLM_TOOL_CALLING.md` - Tool calling 2022-2025 evolution
- `LLM_PROMPT_OPTIMIZATION.md` - Prompt engineering best practices
- `TOKEN_EFFICIENCY_PATTERNS.md` - Cost optimization strategies
- `AI_AGENT_FRAMEWORKS.md` - Framework comparison (ReAct, AutoGPT, etc.)

**Multi-Agent Systems:**
- `MULTI_AGENT_COORDINATION.md` - Coordination patterns
- `MULTI_AGENT_ORCHESTRATION.md` - Orchestration frameworks
- `CONVERSATION_COORDINATION_DESIGN.md` - Dialogue coordination

**Memory & Learning:**
- `CONVERSATIONAL_MEMORY.md` - Memory system design
- `MEMORY_ARCHITECTURES.md` - Memory patterns
- `MEMORY_PERSISTENCE.md` - Memory storage

**Character & Personality:**
- `CHARACTER_AI_SYSTEMS.md` - Personality system design
- `EMOTIONAL_AI_FRAMEWORK.md` - Emotion modeling (OCC)
- `RELATIONSHIP_MILESTONES.md` - Relationship evolution

---

## Citation Standards

### Format

**Inline Citation Format:** [Author, Year]

**Examples:**
- Single author: [Isla, 2005]
- Two authors: [Millington & Funge, 2009]
- Three+ authors: [Lewis et al., 2020]
- Multiple citations: [Isla, 2005; Orkin, 2006]

### Citation Categories

**Game AI Foundations (8 sources)**
- Textbooks: Millington & Funge (2009), Russell & Norvig (2020)
- Collections: Rabin (2010, 2014, 2016)
- Guides: Champandard (2007), Champandard & D√≠az-Guerra (2021)

**Behavior Trees (5 sources)**
- Isla (2005, 2008), Isla & Burke (2006)
- Champandard (2007), Hern√°ndez (2017)

**GOAP (4 sources)**
- Orkin (2004, 2006)
- Hern√°ndez & G√≥mez (2013), Sterren (2005)

**Utility AI (6 sources)**
- Mark (2009), Tozour (2003)
- Hart et al. (1968), Dill (2009), Gormally (2011)

**RTS AI (8 sources)**
- Buro (2004), Weber & Mateas (2009), Weber et al. (2010)
- Synnaeve et al. (2016), Vinyals et al. (2019)

**RPG AI (18 sources)**
- Ultima series: Garriott (1988, 1990, 1992)
- BioWare games: BioWare (1998, 2009)
- Need-based systems: Wright (2000), Forshaw (2014)

**LLM Foundations (6 sources)**
- Transformers: Vaswani et al. (2017), Brown et al. (2020)
- Modern LLMs: OpenAI (2024), Anthropic (2025), Google (2024)

**RAG (5 sources)**
- Lewis et al. (2020), Karpukhin et al. (2020)
- Reimers & Gurevych (2019), Gao et al. (2023)

**Agent Frameworks (5 sources)**
- ReAct: Yao et al. (2022)
- AutoGPT: Graves (2023)
- LangChain: Harrison (2023)
- BabyAGI: Nakajima (2023)

### Quick Reference

**Game AI Citations:**
- Behavior Trees: [Isla, 2005; Champandard, 2007]
- GOAP: [Orkin, 2004; Orkin, 2006]
- Utility AI: [Mark, 2009; Tozour, 2003]
- FSM: [Millington & Funge, 2009]

**RTS-Specific Citations:**
- StarCraft: [Buro, 2004]
- AlphaStar: [Vinyals et al., 2019]

**LLM Citations:**
- Transformers: [Vaswani et al., 2017]
- GPT-4: [OpenAI, 2024]
- RAG: [Lewis et al., 2020]
- ReAct: [Yao et al., 2022]

### Implementation Progress

**Status:** 33 edits identified across 3 chapters

**Chapter 1 (RTS AI):** 12 edits
**Chapter 3 (RPG AI):** 11 edits
**Chapter 8 (LLM Enhancement):** 10 edits

**Reference:** See `CITATION_EDITS_QUICK_REFERENCE.md` for specific edits

---

## Adding New Research

### Research Document Template

```markdown
# Research Title

**Date:** YYYY-MM-DD
**Research Focus:** [Brief description]
**Application:** [How this applies to Steve AI/Dissertation]

---

## Executive Summary

[2-3 sentence overview of key findings]

---

## Table of Contents

1. [Section 1](#section-1)
2. [Section 2](#section-2)
...

---

## Content

[Main research content with code examples, diagrams, etc.]

---

## Key Insights

[Bulleted list of main takeaways]

---

## Integration Notes

[Which chapter(s) this should integrate with]
[Specific sections or line numbers if applicable]

---

## Sources

[Links to references, papers, documentation]

---

**Document Version:** 1.0
**Last Updated:** YYYY-MM-DD
**Author:** [Your name/Agent]
**Status:** [Draft/Review/Complete]
```

### Naming Conventions

**Dissertation Content:**
- `DISSERTATION_CHAPTER_[N]_[TOPIC].md` - Source material
- `DISSERTATION_CHAPTER_[N]_[TOPIC]_IMPROVED.md` - Integrated chapter

**Research Areas:**
- `[TOPIC]_DESIGN.md` - Design patterns
- `[TOPIC]_EVOLUTION.md` - Historical evolution
- `[TOPIC]_DEEP_DIVE.md` - In-depth analysis
- `[TOPIC]_QUICKREF.md` - Quick reference

**Status Documents:**
- `VIVA_VOCE_CYCLE[N]_SYNTHESIS.md` - Examination status
- `CITATION_[STATUS]_SUMMARY.md` - Citation tracking
- `CHAPTER_[N]_INTEGRATION_PLAN.md` - Integration plans

### Research Workflow

1. **Discovery** - Read existing research to avoid duplication
2. **Research** - Gather sources, examples, patterns
3. **Documentation** - Write research document using template
4. **Integration** - Add to appropriate dissertation chapter
5. **Citation** - Add citations to bibliography
6. **Review** - Update status documents

---

## Integration Process

### Integration Workflow

```
[Research Document]
        ‚Üì
[Identify Target Chapter]
        ‚Üì
[Find Integration Point]
        ‚Üì
[Edit Main Chapter]
        ‚Üì
[Add Cross-References]
        ‚Üì
[Update Citation Status]
        ‚Üì
[Verify Flow & Consistency]
        ‚Üì
[Update Integration Tracker]
```

### Integration Best Practices

**1. Preserve Narrative Flow**
- Integrated sections should maintain chapter's thematic progression
- Use transitional paragraphs to connect new content
- Update section numbering consistently

**2. Maintain Academic Rigor**
- Add proper citations for all integrated content
- Include implementation examples where relevant
- Provide comparative analysis when discussing alternatives

**3. Technical Depth**
- Include complete code examples, not snippets
- Provide performance benchmarks
- Add production considerations

**4. Reader Experience**
- Use consistent formatting
- Provide clear section boundaries
- Include cross-references between related sections

### Integration Checklists

**Before Integration:**
- [ ] Read target chapter completely
- [ ] Identify logical integration point
- [ ] Check for duplicate content
- [ ] Gather required citations

**During Integration:**
- [ ] Add transitional paragraphs
- [ ] Update section numbering
- [ ] Add cross-references
- [ ] Include code examples

**After Integration:**
- [ ] Verify narrative flow
- [ ] Check citation consistency
- [ ] Test code examples
- [ ] Update integration tracker

### Integration Status Tracking

**Current Integration Progress:** 85%

**Completed Integrations:**
- ‚úÖ Chapter 1: BT, HTN, Spatial Reasoning, Performance Constraints
- ‚úÖ Chapter 8: RAG, Tool Calling, Framework Comparison, 2024-2025 Techniques
- ‚úÖ Chapter 4: Chunk-aware planning
- ‚úÖ Chapter 6: Multiplayer patterns

**Pending Integrations:**
- üîÑ Chapter 3: Emotional AI sections (~30% remaining)

**Reference:** `DISSERTATION_INTEGRATION_SUMMARY.md` for detailed status

---

## Current Research Priorities

### Priority 1: MUD Automation ‚Üí LLM Learning Principles

**Research Question:** How did 1990s MUD automation solve complex problems without LLMs?

**Key Documents:**
- `MUD_AUTOMATION_LLM_PRINCIPLES.md` - Comprehensive analysis
- `PRE_LLM_GAME_AUTOMATION.md` - Historical patterns

**Approach:**
1. Document MUD automation patterns (triggers, aliases, scripts)
2. Extract reusable principles (event-driven, state-based, hierarchical)
3. Design LLM‚ÜíScript generation pipeline
4. Implement script refinement loop

**Expected Outcome:** System where LLMs generate and refine automation scripts, reducing token usage by 10-20x

### Priority 2: Script Layer Learning System

**Research Question:** How can agents learn from successful execution sequences?

**Key Documents:**
- `SCRIPT_LAYER_LEARNING_SYSTEM.md` - Complete design document
- `SCRIPT_GENERATION_SYSTEM.md` - LLM‚ÜíScript pipeline

**Approach:**
1. Capture successful task sequences
2. Extract as reusable skills (Voyager-style)
3. Store in skill library with semantic indexing
4. Retrieve by similarity for future tasks
5. Refine through iteration

**Expected Outcome:** Self-improving agents that get better with experience

### Priority 3: Multi-Agent Coordination

**Research Question:** How do agents coordinate without central control?

**Key Documents:**
- `MULTI_AGENT_COORDINATION.md` - Coordination patterns
- `MULTI_AGENT_ORCHESTRATION.md` - Orchestration frameworks

**Approach:**
1. Contract Net Protocol (task bidding)
2. Blackboard system (shared knowledge)
3. Event-driven messaging
4. Emergent behavior through simple rules

**Expected Outcome:** Agents that work together seamlessly without explicit orchestration

### Priority 4: Small Model Specialization

**Research Question:** Can small, specialized models outperform large general models?

**Approach:**
1. Train/fine-tune small models for specific tasks (mining, building, combat)
2. Cascade router selects appropriate model
3. Fallback to large model for novel situations

**Expected Outcome:** 40-60% cost reduction while maintaining quality

### Priority 5: Evaluation Framework

**Research Question:** How do we measure agent improvement?

**Key Documents:**
- `EVALUATION_FRAMEWORK.md` - Complete evaluation methodology
- `EVALUATION_QUICK_REFERENCE.md` - Quick start guide
- `run_benchmarks.sh` - Automated benchmark execution
- `analyze_benchmarks.R` - Statistical analysis script

**Approach:**
1. Define metrics (success rate, time to completion, token usage)
2. Create benchmark tasks
3. Automated evaluation pipeline
4. A/B testing for script variants

**Expected Outcome:** Quantifiable evidence of agent improvement over time

---

## Viva Voce Preparation

### Examination Process

**Viva Voce (Oral Defense)** - Academic examination of dissertation

**Cycles:**
- Cycle 1: Initial examination (B+ grade)
- Cycle 2: First revision (A- grade)
- Cycle 3: Second revision (A grade) ‚Üê Current
- Cycle 4: Third revision (A+ target)
- Cycle 5: Final polish (A+ target)

### Examination Committee

**6 Examiners:**
1. RTS Specialist - Chapter 1 focus
2. RPG Specialist - Chapter 3 focus
3. LLM Specialist - Chapter 8 focus
4. Architecture Specialist - Chapter 6 focus
5. Practical Reviewer - Implementation focus
6. Philosophy Examiner - Overall coherence

### Common Examiner Feedback

**Theme 1: Integration Failure** (6/6 examiners)
- **Issue:** Excellent content exists in standalone documents but not integrated into main chapters
- **Status:** 85% resolved
- **Remaining:** Complete Chapter 3 emotional AI integration

**Theme 2: Documentation-Implementation Gap** (3/6 examiners)
- **Issue:** Documentation is production-ready, implementation is prototype
- **Status:** Acknowledged
- **Action:** Implement documented patterns (TickProfiler, ChunkValidator)

**Theme 3: Citation Inconsistency** (4/6 examiners)
- **Issue:** Some sections have excellent citations, others have none
- **Status:** In progress
- **Action:** 33 edits identified across 3 chapters

### Preparation Checklist

**Content Preparation:**
- [ ] All chapters integrated and coherent
- [ ] Citations standardized throughout
- [ ] Limitations sections added
- [ ] Cross-references verified
- [ ] Code examples tested

**Presentation Preparation:**
- [ ] 15-20 minute presentation prepared
- [ ] Key diagrams and figures ready
- [ ] Demo videos (if applicable)
- [ ] Q&A responses rehearsed

**Logistics:**
- [ ] Examination date confirmed
- [ ] Committee requirements met
- [ ] Submission format verified
- [ ] Backup copies prepared

### Key Talking Points

**"One Abstraction Away" Thesis**
- LLMs plan and coordinate, traditional AI executes
- Enables real-time performance (60 FPS) with LLM intelligence
- Reduces token usage by 10-20x

**Multi-Layer Cognitive Architecture**
- Brain layer: LLM strategic planning
- Script layer: Learned automatic behaviors
- Physical layer: Minecraft API interaction

**Novel Contributions**
- MUD automation principles applied to LLM agents
- Script layer learning system
- Hybrid cascade routing for cost optimization
- Multi-agent coordination patterns

---

## Research Resources

### Online Resources

**Academic Papers:**
- Google Scholar: https://scholar.google.com
- arXiv.org: https://arxiv.org
- ACM Digital Library: https://dl.acm.org
- IEEE Xplore: https://ieeexplore.ieee.org

**Game AI Research:**
- GDC Vault: https://www.gdcvault.com
- AI Game Dev: https://www.gameai.com
- Game Programming Patterns: https://gameprogrammingpatterns.com

**LLM Research:**
- OpenAI Research: https://openai.com/research
- Anthropic Research: https://www.anthropic.com/research
- LangChain Documentation: https://docs.langchain.com

### Project-Specific Resources

**Source Code:**
- Main Codebase: `C:\Users\casey\steve\src\main\java\com\minewright\`
- Test Code: `C:\Users\casey\steve\src\test\java\com\minewright\`
- Build Scripts: `C:\Users\casey\steve\build.gradle`

**Documentation:**
- Project Guide: `C:\Users\casey\steve\CLAUDE.md`
- Research Index: `C:\Users\casey\steve\docs\research\README.md`
- This Guide: `C:\Users\casey\steve\docs\RESEARCH_GUIDE.md`

**Configuration:**
- Config File: `C:\Users\casey\steve\config\steve-common.toml`
- Build Output: `C:\Users\casey\steve\build\libs\`

### Getting Help

**For Research Questions:**
1. Check existing research documents in `docs/research/`
2. Review `README.md` for research library index
3. Consult key research documents listed above
4. Check citation standards before adding references

**For Implementation Questions:**
1. Review code examples in research documents
2. Check `CLAUDE.md` for implementation patterns
3. Examine source code in `src/main/java/com/minewright/`
4. Refer to evaluation framework for testing

**For Dissertation Questions:**
1. Review `VIVA_VOCE_CYCLE2_SYNTHESIS.md` for current status
2. Check `DISSERTATION_INTEGRATION_SUMMARY.md` for integration progress
3. Consult `CITATION_STANDARDIZATION_SUMMARY.md` for citation guidelines
4. Review chapter-specific improved files for latest content

---

## Summary

The Steve AI project is a sophisticated research endeavor combining practical game development with academic contribution. With **108+ research documents** covering game AI history, LLM integration patterns, cognitive architectures, and evaluation methodologies, the project provides a comprehensive foundation for understanding modern AI agent development.

**Current Status:**
- Dissertation grade: A (94/100), approaching A+
- Integration progress: 85% complete
- Research documentation: Comprehensive and well-organized
- Implementation: Production-ready architecture, prototype features

**Next Steps:**
1. Complete Chapter 3 emotional AI integration
2. Add 2024-2025 LLM technique coverage
3. Standardize citations across all chapters
4. Implement documented patterns (TickProfiler, ChunkValidator)
5. Complete evaluation framework implementation

This research guide provides navigation for the extensive research library, citation standards, integration processes, and current priorities. Use it to orient yourself when contributing to the research side of the Steve AI project.

---

**Document Version:** 1.0
**Last Updated:** 2026-02-28
**Maintained By:** Research Team
**Next Review:** After Cycle 3 Viva Voce

---

**End of Research Guide**
